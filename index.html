<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning">
    <meta name="keywords" content="text-to-image generation, Large Language Models, scene synthesis">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MMFinBench</title> 

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
    <link rel="icon" href="./static/images/logo.png">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <link rel="stylesheet" href="./static/css/index-gradio.css">
    <link rel="stylesheet" href="./static/css/live_theme.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title"
                        style="display: flex;flex-direction: row;align-items: center;justify-content: center;margin-bottom: 5px;"><img
                            src="./static/images/logo.png" width="60" height="60" style="margin-right: 10px;">MME-Finance:</h1>
                    <h1 class="title is-2 publication-title">A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              Ziliang Gan<sup>1</sup> </a>,
               Dong Zhang<sup>1</sup>, Haohan Li<sup>1</sup>, Yang Wu<sup>1</sup>, Xueyuan Lin<sup>4ï¼Œ1</sup>, Ji Liu<sup>1</sup>,
              Haipang Wu<sup>1</sup> </a>,
            </span>
            <br>
            <span class="author-block">
                Chaoyou Fu<sup>3</sup>, Zenglin Xu<sup>4</sup>, Rongjunchen Zhang<sup>1</sup>, Yong Dai<sup>1</sup>
            </span>
                    </div>
                    <div class="is-size-5 publication-authors" style="margin-top: 10px;">
                        <span class="author-block">
                            <sup>1</sup>Hithink Research, <sup>2</sup>Imperical College London, <sup>3</sup>Nanjing University, <sup>4</sup>Fudan University, <sup>5</sup>The HongKong University of Science and Technology (Guangzhou), <sup>6</sup>IDEA Research
                        </span>

                    </div>

    </div>
</section>

<div class="column has-text-centered">
    <div class="publication-links">
      <!-- PDF Link. -->
      <span class="link-block"> <a href="https://arxiv.org/abs/2411.03314"
           class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="ai ai-arxiv"></i> </span> <span>arXiv</span> </a> </span>
      <!-- Code Link. -->
      <span class="link-block"> <a href="https://github.com/HiThink-Research/MME-Finance.git"
           class="external-link button is-normal is-rounded is-dark"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span>
      <!-- HuggingFace Link. -->
      <span class="link-block"> <a href="https://huggingface.co/datasets/hithink-ai/MME-Finance"
           class="external-link button is-normal is-rounded is-dark"><span class="icon">ðŸ¤—</span><span>Space</span> </a></span>
      <span class="link-block"> <a href="https://github.com/HiThink-Research/MME-Finance/blob/main/Supplementary_pdf_ACMMM.pdf"
           class="external-link button is-normal is-rounded is-dark"> <span class="icon">ðŸ“– </span> <span>Supplementary PDF for ACM MM</span> </a> </span>
    </div>
      </div>



<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-2">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        To date, there is a notable lack of rigorous benchmarks that assess Multimodal Large Language Models (MLLMs) within the financial domainï¼Œa field characterized by specialized financial charts and complex domain-specific expertise.
  To address this gap, we introduce MME-Finance, the first comprehensive bilingual multimodal benchmark tailored for financial analysis. MME-Finance comprises 4,751 meticulously curated samples, encompassing 2,274 open-ended questions, 2,000 binary-choice questions, and 477 multi-turn questions.
  To mitigate bias when LLMs act as judges, we also created an evaluation framework that strengthens alignment with human judgments by embedding visual context into the multimodal assessment pipeline. A comprehensive evaluation of 31 popular MLLMs has been conducted to assess their perception, reasoning, and cognitive capabilities. 
  Gemini2.5Pro achieves highest accuracy of 79.28\% and 85.71\% on the open-ended questions and multi-turn questions, respectively. Among open-source models, InternVL3-78B attains 71.24 \% accuracy on the open-ended question, whereas Qwen2.5-VL-72B achieves an F1 score of 88.73 \% on the binary-choice question.
  The results indicate that state-of-the-art MLLMs demonstrate considerable overall competence, yet exhibit significant deficiencies in fine-grained visual perception and the understanding of domain-specific financial images.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Overview</h2>
            <br>
        </div>
        <!-- Architecture -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h4 class="title is-3">â€¢Data Collection </h4>
                <div class="content has-text-justified">
                    <p>
                        This is the data collection pipeline of MME-Finance. 
                        First, we identify relevant financial pages on a computer and use screenshot tools to capture the appropriate areas. Then, we use mobile devices to photograph the corresponding sections. 
                        Next, we search for the same content on mobile applications and capture screenshots using smartphones. 
                        The inclusion of diverse image styles, including computer screenshots, mobile photographs, and vertical and horizontal mobile screenshots, is intended to simulate real-world application scenarios. 
                        MME-Finance categorizes the collected images into six types: candlestick charts, technical indicator charts, statistical charts, tables, documents, and mixed charts. 

                    </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/Collection.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #1d3f9c;">
                        </p>
                    </figcaption>
                </div>
                <h4 class="title is-3">â€¢QA Generation</h4>
                    <p>
                        This is the annotation pipeline on MME-Finance. GPT-4o is utilized to generate questions and corresponding answers. 
                        These results are reviewd by experts to make sure the quality of MME-Finance.
                    </p>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/Annotation.png" alt="Teaser" width="95%"
                        style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
                <h4 class="title is-3">â€¢Evaluation Method </h4>
                    <div class="content has-text-justified">
                        <p>
                            This is the evaluation pipeline on MME-Finance. 
                            MME-Finance designs a comprehensive evaluation process tailored to the characteristics of our benchmark. 
                            During the inference phase, prompts are crafted to constrain the output formats of MLLMs, thereby facilitating a more standardized evaluation. 
                            LLM-based evaluation system is used to score the performance of various models. 
                            The scoring system is divided into six levels, ranging from 0 (completely incorrect) to 5 (fully correct), with the overall score being the average across all samples. 
                        </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/infer_eval.png" alt="Teaser" width="95%"
                        style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
                <h4 class="title is-3">â€¢Statistics </h4>
                    <div class="content has-text-justified">
                        <p>
                            This is the statistics results of open-ended version of MME-Finance. MME-Finance contains 1,171 English and 1,103 Chinese image-question-answer pairs spanning 11 distinct tasks, categorized into 3 ability levels. 
                            In addition, MME-Finance incorporates questions aimed at evaluating hallucinations of MLLMs. 
                            The number of samples per task varies from 42 to 395, with the "Spatial Awareness" task containing the most and "Reason Explanation" the fewest. 
                            The above image illustrates the distribution of the 6 image types, where statistical charts account for the main proportion, while mixed charts are the least. 
                            The below image displays the distribution of 4 image styles. Computer screenshots and mobile photographs constitute similar proportions, representing 42.9% and 40.5% of the total, respectively. 
                            Horizontal mobile screenshots contain fewest samples.
                            Vertical and horizontal mobile screenshots contain approximately sample sizes. 
                        </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/stat.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    <figcaption>
                        <p style="text-align: center; color: #061E61;">
                        </p>
                    </figcaption>
                    </div>
            </div>
        </div>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Results on MME-Finance</h2>
            <br>
        </div>
        <div class="columns is-centered">
            <div class="column is-full-width"> 
                <div class="content has-text-justified">
                    <p>
                        The below table shows the results of various MLLMs on English open-ended version, binary-choice version, and multi-turn version of MME-Finance. For the open-ended version, performance across the MLLMs varies significantly, with many models exhibiting low accuracy, highlighting the challenging nature of the MME-Finance. Among all the evaluated models, Gemini2.5Pro achieves the best overall performance with 79.28% accuracy, excelling in most tasks, particularly OCR and SA. GPT-4o and InternVL3-78B rank second and third, respectively. 
Furthermore, the experimental results support the observation of MMBench that the size of the language model has a significant impact on performance. For the binary-choice version of MME-Finance, the results of all the models are quite good. GPT-4o, Qwen2.5VL-72B, and Gemini2.5Pro achieve the top three results. For the multi-turn version, Gemini2.5Pro is the best, followed by Claude3.5-sonnet, and then Qwen2.5VL-72B. Overall, for the MME-Finance, the proprietary models demonstrated superior performance. Nevertheless, the leading open-source model exhibited only a marginal difference in effectiveness.
                    </p>
                    <img class="columns is-centered has-text-centered" src="./static/images/results.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>



<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <h2 class="title is-2">Demonstrations</h2>
            <br>
        </div>
        <div class="columns is-centered">
            <div class="column is-full-width"> 
                <h3 class="title is-4">â€¢Open-ended version</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/image_caption.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    </div>
                <!-- <h3 class="title is-4">â€¢Spatial Awareness</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="./static/images/spatial_awareness.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    </div> -->
                <h3 class="title is-4">â€¢Binary-choice version</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="static/images/true_false.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                    <br>
                    </div>
                <h3 class="title is-4">â€¢Multi-turn version</h3>
                    <div class="content has-text-justified">
                    <img class="columns is-centered has-text-centered" src="static/images/multi-turn.png" alt="Teaser" width="95%"
                         style="margin:0 auto">
                <br>
                    </div>
                    </div>
</section>


</section>
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista_other" id="citation">Citation</h1>
  </div>
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <pre><code>
    @article{gan2024woodpecker,
      title={MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning},
      author={Gan, Ziliang and Lu, Yu and Zang, Dong and Li, Haohan and Liu, Che and Liu, Jian and Liu, Ji and Wu, Haipang and Fu, Chaoyou and Xu, Zenglin and Zhang, Rongjunchen and Dai, Yong},
      journal={arXiv preprint arXiv:2411.03314},
      year={2024}
    }
</code></pre>
  </div>
</section>
